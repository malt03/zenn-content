---
title: "手書き数字の分類"
---

# ゴール

この章のゴールは、画像分類モデルを

# 開発環境

:::details 前章と同じです。

[uv](https://zenn.dev/malt03/books/d3f6cd9caa864a/viewer/999_environment#uv) をインストールしてください。

:::

### ディレクトリ

本章では、`./mnist` 配下のコードを解説します。  
ディレクトリに移動し、 `sync` を実行してください。

```sh
cd ./mnist
uv sync
```

# 実行してみよう

### 学習データの表示

今回は、MNIST と呼ばれる手書き数字の画像データを使って、画像分類モデルを作成します。
まずは、学習データを表示してみましょう。

```
uv run ./src/show_mnist.py
```

初回実行時はデータのダウンロードが必要なため、少し時間がかかります。
その後、手書き数字にラベル付けされたデータが表示されます。

今回は、このデータを使って 4 と 9 を分類するモデルを作成します。
4 と 9 は形が似ているため、分類が特に難しい数字の組み合わせです。

![4-9](/images/d3f6cd9caa864a/2_mnist/4-9.png)
_どっち？_

### 学習

それでは、学習を実行します。
今回は少し時間がかかります。

```
uv run ./src/train.py
```

40 エポック実行され、以下のような画像が表示されます。

![result](/images/d3f6cd9caa864a/2_mnist/result.png)

# 解説

### 学習曲線

最後に出力された学習曲線について説明していきます。

このグラフには、各エポックごとの学習の状況を記録して表示しています。
こういったグラフは実際の学習でも必ず作成して、学習がうまくいっているかを確認します。

グラフには 3 つの曲線があります。

| 線の色 | 説明                             |
| :----: | :------------------------------- |
|   青   | トレーニングデータに対する損失値 |
|   緑   | テストデータに対する損失値       |
|   赤   | テストデータに対する分類の正解率 |

新しいキーワードとして「トレーニングデータ」と「テストデータ」が出てきました。

### トレーニングデータとテストデータ

トレーニングデータとは、モデルを学習させるために使われるデータです。モデルはこのデータを使ってパターンを見つけ、分類や予測を行えるようになります。いわば「勉強用の教材」のようなものです。
前章の 2D ポイント分類モデルでは、全てのデータをトレーニングデータとして使っていました。

一方、テストデータは、モデルが学習した内容を評価するために使われるデータです。
テストデータはトレーニングそのものには使わず、各エポックで学習が終わった後にモデルの性能を確認するために用いられます。

トレーニングデータとテストデータを分けて用いる理由は、モデルが勉強した内容を暗記するだけではなく、新しいデータに対しても適切な予測を行えるかをチェックするためです。
これを確認することで、モデルの汎化性能（新しいデータに対する対応力）を評価することができます。

### 具体的な学習曲線の解釈

- **青の線（トレーニングデータの損失値）**  
  学習が進むにつれて、トレーニングデータに対する損失値が徐々に下がるのが理想です。
  これは、モデルがトレーニングデータに含まれるパターンを学習していることを意味します。
- **緑の線（テストデータの損失値）**  
  テストデータの損失値も、トレーニングデータと同じように下がるのが望ましいです。ただし、トレーニングデータよりもやや高い値になるのが一般的です。  
  学習が進むと、テストデータの損失値は増加に転じます。これは**過学習**が始まったことを示します。
- **赤の線（テストデータの分類の正解率）**  
  損失値だけでは、学習が進んでいるかを直感的に判断しにくい場合があります。正解率は、モデルがテストデータをどれだけ正確に分類できたかの割合を表したもので、損失値の補助的な指標として活用されます。  
  正解率が高いほどモデルの分類能力が良いことを示しますが、損失値との組み合わせで学習の状況を総合的に判断します。

#### 過学習

ディープラーニングでは、学習が進むと必ず**過学習**が発生します。過学習とは、モデルがトレーニングデータに過剰に適応し、テストデータに対する損失値が増加し始める現象です。

過学習の状態では、モデルはトレーニングデータ特有のパターンまで学習してしまうため、**新しいデータに対応する能力（汎化性能）**が低下します。
一見するとトレーニングデータに対しては高精度なモデルに見えますが、テストデータに対する性能は下がります。

しかし、**過学習自体はネガティブなことではありません**。過学習が全く起きない場合、モデルがまだ十分にパターンを学習しきれていません。
この場合、さらに学習を進めたり、モデルをより複雑にすることで、トレーニングデータからより多くのパターンを学習させる必要があります。

### ディープラーニングの基本的なフロー

ディープラーニングのモデルを作成する際、基本的に最初から学習がうまくいくことはありません。
学習がうまくいかない場合に対処すべき問題を、解決すべき順番に、対処方法とともに解説します。

#### 1. トレーニングデータの損失値が下がらない

この問題は簡単に対処が可能です。
ディープラーニングでは、ランダムな値さえも学習できることを思い出してください。
あなたが試すことはただ一つ、モデルのパラメータを増やしてみることです。
層を増やしたり、各層が持つパラメータを増やしてみましょう。
学習時間は増加しますが、トレーニングデータに対する損失値は**必ず**下げることが可能です。

:::message
計算リソースが足りない場合は、高性能なマシンやクラウドサービス（例: Google Colab）を活用すると良いでしょう。
:::

#### 2. テストデータに対する正解率がベースライン以上にならない

学習の際には、**ベースライン**を定めることが重要です。  
ベースラインは、モデルが最低限達成すべき性能の基準であり、ランダムに選択した場合に達成できる値を基に設定します。

今回の場合、2 クラス分類であるため、ランダムに選択しても正解率は 0.5 になることから、**「正解率 0.5 以上」をベースライン**とするべきです。モデルの正解率がこのベースラインを超えられない場合、全く学習できていないのと同じです。

トレーニングデータの損失値は下がるのに、テストデータの正解率がベースライン以上に改善しない場合、これはかなり深刻な問題です。
モデルが入力データからパターンを学習できていないことを示しており、この状態ではモデルがランダムな値を出力しているのと変わりません。

**確認すべきポイント**  
このような場合、以下の点を確認しましょう。

- **この問題は客観的に見て学習が可能な問題か**  
  例えば、「4」と「9」を分類する問題はパターンがあるため学習可能ですが、完全にランダムなデータを学習することはできません。
- **学習データは正しくラベリングされているか**  
  データのラベルに誤りがあると、モデルが正しいパターンを学習できません。データセットを一部確認し、ラベルが正確かどうかをチェックしましょう。
- **実装は正しく行われているか**  
  損失関数が問題に適したものになっているか、データの入力は正しく行われているか再確認しましょう。

#### 3. 過学習が起きない

上記の通り、ディープラーニングでは学習が十分に進むと必ず過学習が発生します。過学習が全く起きない場合、モデルがトレーニングデータに含まれるパターンを十分に学習しきれていない可能性があります。

この状態では、モデルの予測性能が十分に高まらないため、以下のような確認と対処が必要です。

- **エポック数を増やす**
  学習回数が不十分だと、モデルがトレーニングデータを十分に学習しきれないことがあります。エポック数を増やして学習を継続し、モデルがデータに含まれるパターンをさらに学習できるようにしましょう。
- **モデルのパラメータをさらに増やす**
  モデルが複雑さに欠けている場合、データ内の複雑なパターンを学習することができません。層を追加したり、各層のパラメータ数を増やすことで、モデルの学習能力を向上させることができます。
- **テストデータにトレーニングデータが紛れ込んでしまっていないか確認する**
  テストデータとトレーニングデータが重複している場合、過学習が起きないように見えることがあります。これは、モデルがトレーニングデータを暗記しているためです。データセットを再確認し、重複がないように分割を適切に行ってください。
