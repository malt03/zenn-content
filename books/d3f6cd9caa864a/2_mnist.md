---
title: "手書き数字の分類"
---

# ゴール

この章のゴールは、画像分類モデルを

# 開発環境

:::details 前章と同じです。

[uv](https://zenn.dev/malt03/books/d3f6cd9caa864a/viewer/999_environment#uv) をインストールしてください。

:::

### ディレクトリ

本章では、`./mnist` 配下のコードを解説します。  
ディレクトリに移動し、 `sync` を実行してください。

```sh
cd ./mnist
uv sync
```

# 実行してみよう

### 学習データの表示

今回は、MNIST と呼ばれる手書き数字の画像データを使って、画像分類モデルを作成します。
まずは、学習データを表示してみましょう。

```
uv run ./src/show_mnist.py
```

初回実行時はデータのダウンロードが必要なため、少し時間がかかります。
その後、手書き数字にラベル付けされたデータが表示されます。

今回は、このデータを使って 4 と 9 を分類するモデルを作成します。
4 と 9 は形が似ているため、分類が特に難しい数字の組み合わせです。

![4-9](/images/d3f6cd9caa864a/2_mnist/4-9.png)
_どっち？_

### 学習

それでは、学習を実行します。
今回は少し時間がかかります。

```
uv run ./src/train.py
```

40 エポック実行され、以下のような画像が表示されます。

![result](/images/d3f6cd9caa864a/2_mnist/result.png)

# 解説

### 学習曲線

最後に出力された学習曲線について説明していきます。

このグラフには、各エポックごとの学習の状況を記録して表示しています。
こういったグラフは実際の学習でも必ず作成して、学習がうまくいっているかを確認します。

グラフには 3 つの曲線があります。

| 線の色 | 説明                             |
| :----: | :------------------------------- |
|   青   | トレーニングデータに対する損失値 |
|   緑   | テストデータに対する損失値       |
|   赤   | テストデータに対する分類の正解率 |

新しいキーワードとして「トレーニングデータ」と「テストデータ」が出てきました。

### トレーニングデータとテストデータ

トレーニングデータとは、モデルを学習させるために使われるデータです。モデルはこのデータを使ってパターンを見つけ、分類や予測を行えるようになります。いわば「勉強用の教材」のようなものです。
前章の 2D ポイント分類モデルでは、全てのデータをトレーニングデータとして使っていました。

一方、テストデータは、モデルが学習した内容を評価するために使われるデータです。
テストデータはトレーニングそのものには使わず、各エポックで学習が終わった後にモデルの性能を確認するために用いられます。

トレーニングデータとテストデータを分けて用いる理由は、モデルが勉強した内容を暗記するだけではなく、新しいデータに対しても適切な予測を行えるかをチェックするためです。
これを確認することで、モデルの汎化性能（新しいデータに対する対応力）を評価することができます。

### 具体的な学習曲線の解釈

- **青の線（トレーニングデータの損失値）**
  学習が進むにつれて、トレーニングデータに対する損失値が徐々に下がるのが理想です。これにより、モデルが与えられたデータをうまく学習していることがわかります。
- **緑の線（テストデータの損失値）**
  テストデータの損失値も、トレーニングデータと同じように下がるのが望ましいです。ただし、トレーニングデータよりも高い値になることが多いです。これが極端に大きい場合、モデルがトレーニングデータを暗記しているだけで、新しいデータに対応できていない可能性があります。
- **赤の線（テストデータの分類の正解率）**
  損失値だけでは、学習がうまく進んでいるかを直感的に判断しにくい場合が多いです。このような場合、正解率のような分かりやすい指標を確認します。
  正解率は、テストデータが何割のデータを正確に分類できたかを表したものです。損失値との両方を見て、学習がうまくいっているか判断します。

### ディープラーニングの基本的なフロー

ディープラーニングのモデルを作成する際、基本的に最初から学習がうまくいくことはありません。
学習がうまくいかない場合に対処すべき問題を、解決すべき順番に、対処方法とともに解説します。

#### 1. トレーニングデータの損失値が下がらない

この問題は簡単に対処が可能です。
ディープラーニングでは、ランダムな値さえも学習できることを思い出してください。
あなたが試すことはただ一つ、モデルのパラメータを増やしてみることです。
層を増やしたり、各層が持つパラメータを増やしてみましょう。
学習時間は増加しますが、トレーニングデータに対する損失値は**必ず**下げることが可能です。

:::message
計算リソースが足りない場合は、高性能なマシンやクラウドサービス（例: Google Colab）を活用すると良いでしょう。
:::

#### 2. テストデータに対する正解率がベースライン以上にならない

学習の際には、**ベースライン**を定めることが重要です。  
ベースラインは、モデルが最低限達成すべき性能の基準であり、ランダムに選択した場合に達成できる値を基に設定します。

今回の場合、2 クラス分類であるため、ランダムに選択しても正解率は 0.5 になることから、**「正解率 0.5 以上」をベースライン**とするべきです。モデルの正解率がこのベースラインを超えられない場合、全く学習できていないのと同じです。

トレーニングデータの損失値は下がるのに、テストデータの正解率がベースライン以上に改善しない場合、これはかなり深刻な問題です。
モデルが入力データからパターンを学習できていないことを示しており、この状態ではモデルがランダムな値を出力しているのと変わりません。

**確認すべきポイント**  
このような場合、以下の点を確認しましょう。

- **この問題は客観的に見て学習が可能な問題か**  
  例えば、「4」と「9」を分類する問題はパターンがあるため学習可能ですが、完全にランダムなデータを学習することはできません。
- **学習データは正しくラベリングされているか**  
  データのラベルに誤りがあると、モデルが正しいパターンを学習できません。データセットを一部確認し、ラベルが正確かどうかをチェックしましょう。
- **実装は正しく行われているか**  
  損失関数が問題に適したものになっているか、データの入力は正しく行われているか再確認しましょう。

#### 3.
